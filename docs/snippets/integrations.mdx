{/* Auto-generated by scripts/mdx_snippets_gen.py. Do not edit manually. */}

export const PyEmbeddingAwsUsage = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport pandas as pd\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\nmodel = get_registry().get(\"bedrock-text\").create()\n\nclass TextModel(LanceModel):\n    text: str = model.SourceField()\n    vector: Vector(model.ndims()) = model.VectorField()\n\ndf = pd.DataFrame({\"text\": [\"hello world\", \"goodbye world\"]})\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"bedrock-demo\"))\ntbl = db.create_table(\"test\", schema=TextModel, mode=\"overwrite\")\n\ntbl.add(df)\nrs = tbl.search(\"hello\").limit(1).to_pandas()\nprint(rs.head())\n";

export const PyEmbeddingCohereUsage = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import EmbeddingFunctionRegistry\nfrom lancedb.pydantic import LanceModel, Vector\n\ncohere = (\n    EmbeddingFunctionRegistry.get_instance()\n    .get(\"cohere\")\n    .create(name=\"embed-multilingual-v2.0\")\n)\n\nclass TextModel(LanceModel):\n    text: str = cohere.SourceField()\n    vector: Vector(cohere.ndims()) = cohere.VectorField()\n\ndata = [{\"text\": \"hello world\"}, {\"text\": \"goodbye world\"}]\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"cohere-demo\"))\ntbl = db.create_table(\"test\", schema=TextModel, mode=\"overwrite\")\ntbl.add(data)\n";

export const PyEmbeddingColpaliSetup = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport pandas as pd\nimport requests\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, MultiVector\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"colpali-demo\"))\nfunc = get_registry().get(\"colpali\").create()\n\nclass Images(LanceModel):\n    label: str\n    image_uri: str = func.SourceField()\n    image_bytes: bytes = func.SourceField()\n    vector: MultiVector(func.ndims()) = func.VectorField()\n    vec_from_bytes: MultiVector(func.ndims()) = func.VectorField()\n\ntable = db.create_table(\"images\", schema=Images)\nlabels = [\"cat\", \"dog\", \"horse\"]\nuris = [\n    \"http://farm1.staticflickr.com/53/167798175_7c7845bbbd_z.jpg\",\n    \"http://farm9.staticflickr.com/8387/8602747737_2e5c2a45d4_z.jpg\",\n    \"http://farm9.staticflickr.com/8216/8434969557_d37882c42d_z.jpg\",\n]\nimage_bytes = [requests.get(uri).content for uri in uris]\ntable.add(\n    pd.DataFrame({\"label\": labels, \"image_uri\": uris, \"image_bytes\": image_bytes})\n)\n";

export const PyEmbeddingColpaliTextSearch = "actual = (\n    table.search(\"a furry pet\", vector_column_name=\"vector\")\n    .limit(1)\n    .to_pydantic(Images)[0]\n)\nprint(actual.label)\n";

export const PyEmbeddingGeminiUsage = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport pandas as pd\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\nmodel = get_registry().get(\"gemini-text\").create()\n\nclass TextModel(LanceModel):\n    text: str = model.SourceField()\n    vector: Vector(model.ndims()) = model.VectorField()\n\ndf = pd.DataFrame({\"text\": [\"hello world\", \"goodbye world\"]})\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"gemini-demo\"))\ntbl = db.create_table(\"test\", schema=TextModel, mode=\"overwrite\")\n\ntbl.add(df)\nrs = tbl.search(\"hello\").limit(1).to_pandas()\nprint(rs.head())\n";

export const PyEmbeddingHuggingfaceUsage = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport pandas as pd\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"huggingface-demo\"))\nmodel = get_registry().get(\"huggingface\").create(name=\"facebook/bart-base\")\n\nclass Words(LanceModel):\n    text: str = model.SourceField()\n    vector: Vector(model.ndims()) = model.VectorField()\n\ndf = pd.DataFrame({\"text\": [\"hi hello sayonara\", \"goodbye world\"]})\ntable = db.create_table(\"greets\", schema=Words)\ntable.add(df)\nquery = \"old greeting\"\nactual = table.search(query).limit(1).to_pydantic(Words)[0]\nprint(actual.text)\n";

export const PyEmbeddingIbmUsage = "import os\nimport tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import EmbeddingFunctionRegistry\nfrom lancedb.pydantic import LanceModel, Vector\n\nwatsonx_embed = (\n    EmbeddingFunctionRegistry.get_instance()\n    .get(\"watsonx\")\n    .create(\n        name=\"ibm/slate-125m-english-rtrvr\",\n        api_key=os.environ.get(\"WATSONX_API_KEY\"),\n        project_id=os.environ.get(\"WATSONX_PROJECT_ID\"),\n    )\n)\n\nclass TextModel(LanceModel):\n    text: str = watsonx_embed.SourceField()\n    vector: Vector(watsonx_embed.ndims()) = watsonx_embed.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"watsonx-demo\"))\ntbl = db.create_table(\"watsonx_test\", schema=TextModel, mode=\"overwrite\")\ntbl.add(data)\n\nrs = tbl.search(\"hello\").limit(1).to_pandas()\nprint(rs.head())\n";

export const PyEmbeddingImagebindAudioSearch = "query_audio = \"./assets/car_audio2.wav\"\nactual = table.search(query_audio).limit(1).to_pydantic(ImageBindModel)[0]\nprint(actual.text == \"car\")\n";

export const PyEmbeddingImagebindImageSearch = "query_image = \"./assets/dog_image2.jpg\"\nactual = table.search(query_image).limit(1).to_pydantic(ImageBindModel)[0]\nprint(actual.text == \"dog\")\n";

export const PyEmbeddingImagebindSetup = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\ndb = lancedb.connect(\"/tmp/imagebind-db\")\nfunc = get_registry().get(\"imagebind\").create()\n\nclass ImageBindModel(LanceModel):\n    text: str\n    image_uri: str = func.SourceField()\n    audio_path: str\n    vector: Vector(func.ndims()) = func.VectorField()\n\ntext_list = [\"A dog.\", \"A car\", \"A bird\"]\nimage_paths = [\n    \"./assets/dog_image.jpg\",\n    \"./assets/car_image.jpg\",\n    \"./assets/bird_image.jpg\",\n]\naudio_paths = [\n    \"./assets/dog_audio.wav\",\n    \"./assets/car_audio.wav\",\n    \"./assets/bird_audio.wav\",\n]\n\ninputs = [\n    {\"text\": a, \"audio_path\": b, \"image_uri\": c}\n    for a, b, c in zip(text_list, audio_paths, image_paths)\n]\n\ntable = db.create_table(\"img_bind\", schema=ImageBindModel)\ntable.add(inputs)\n";

export const PyEmbeddingImagebindTextSearch = "query = \"an animal which flies and tweets\"\nactual = table.search(query).limit(1).to_pydantic(ImageBindModel)[0]\nprint(actual.text == \"bird\")\n";

export const PyEmbeddingInstructorUsage = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\ninstructor = (\n    get_registry()\n    .get(\"instructor\")\n    .create(\n        source_instruction=\"represent the document for retrieval\",\n        query_instruction=\"represent the document for retrieving the most similar documents\",\n    )\n)\n\nclass Schema(LanceModel):\n    vector: Vector(instructor.ndims()) = instructor.VectorField()\n    text: str = instructor.SourceField()\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"instructor-demo\"))\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\n\ntexts = [\n    {\n        \"text\": \"Capitalism has been dominant in the Western world since the end of feudalism.\"\n    },\n    {\n        \"text\": \"The disparate impact theory is especially controversial under the Fair Housing Act.\"\n    },\n    {\n        \"text\": \"Disparate impact in United States labor law refers to practices in employment.\"\n    },\n]\n\ntbl.add(texts)\n";

export const PyEmbeddingJinaMultimodal = "import os\nimport tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport pandas as pd\nimport requests\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\nos.environ[\"JINA_API_KEY\"] = os.environ.get(\"JINA_API_KEY\", \"jina_*\")\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"jina-images\"))\nfunc = get_registry().get(\"jina\").create()\n\nclass Images(LanceModel):\n    label: str\n    image_uri: str = func.SourceField()\n    image_bytes: bytes = func.SourceField()\n    vector: Vector(func.ndims()) = func.VectorField()\n    vec_from_bytes: Vector(func.ndims()) = func.VectorField()\n\ntable = db.create_table(\"images\", schema=Images)\nlabels = [\"cat\", \"cat\", \"dog\", \"dog\", \"horse\", \"horse\"]\nuris = [\n    \"http://farm1.staticflickr.com/53/167798175_7c7845bbbd_z.jpg\",\n    \"http://farm1.staticflickr.com/134/332220238_da527d8140_z.jpg\",\n    \"http://farm9.staticflickr.com/8387/8602747737_2e5c2a45d4_z.jpg\",\n    \"http://farm5.staticflickr.com/4092/5017326486_1f46057f5f_z.jpg\",\n    \"http://farm9.staticflickr.com/8216/8434969557_d37882c42d_z.jpg\",\n    \"http://farm6.staticflickr.com/5142/5835678453_4f3a4edb45_z.jpg\",\n]\nimage_bytes = [requests.get(uri).content for uri in uris]\ntable.add(\n    pd.DataFrame({\"label\": labels, \"image_uri\": uris, \"image_bytes\": image_bytes})\n)\n";

export const PyEmbeddingJinaText = "import os\nimport tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import EmbeddingFunctionRegistry\nfrom lancedb.pydantic import LanceModel, Vector\n\nos.environ[\"JINA_API_KEY\"] = os.environ[\"JINA_API_KEY\"]\n\njina_embed = (\n    EmbeddingFunctionRegistry.get_instance()\n    .get(\"jina\")\n    .create(name=\"jina-embeddings-v2-base-en\")\n)\n\nclass TextModel(LanceModel):\n    text: str = jina_embed.SourceField()\n    vector: Vector(jina_embed.ndims()) = jina_embed.VectorField()\n\ndata = [{\"text\": \"hello world\"}, {\"text\": \"goodbye world\"}]\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"jina-text\"))\ntbl = db.create_table(\"test\", schema=TextModel, mode=\"overwrite\")\n\ntbl.add(data)\n";

export const PyEmbeddingOllamaUsage = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"ollama-demo\"))\nfunc = get_registry().get(\"ollama\").create(name=\"nomic-embed-text\")\n\nclass Words(LanceModel):\n    text: str = func.SourceField()\n    vector: Vector(func.ndims()) = func.VectorField()\n\ntable = db.create_table(\"words\", schema=Words, mode=\"overwrite\")\ntable.add(\n    [\n        {\"text\": \"hello world\"},\n        {\"text\": \"goodbye world\"},\n    ]\n)\n\nquery = \"greetings\"\nactual = table.search(query).limit(1).to_pydantic(Words)[0]\nprint(actual.text)\n";

export const PyEmbeddingOpenaiBasic = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\ndb_path = Path(tempfile.mkdtemp()) / \"openai-embeddings\"\ndb = lancedb.connect(str(db_path))\nfunc = get_registry().get(\"openai\").create(name=\"text-embedding-ada-002\")\n\nclass Words(LanceModel):\n    text: str = func.SourceField()\n    vector: Vector(func.ndims()) = func.VectorField()\n\ntable = db.create_table(\"words\", schema=Words, mode=\"overwrite\")\ntable.add(\n    [\n        {\"text\": \"hello world\"},\n        {\"text\": \"goodbye world\"},\n    ]\n)\n\nquery = \"greetings\"\nactual = table.search(query).limit(1).to_pydantic(Words)[0]\nprint(actual.text)\n";

export const PyEmbeddingOpenclipImageSearch = "import io\n\nfrom PIL import Image\n\nquery_image_uri = \"http://farm1.staticflickr.com/200/467715466_ed4a31801f_z.jpg\"\nimage_bytes = requests.get(query_image_uri).content\nquery_image = Image.open(io.BytesIO(image_bytes))\nactual = table.search(query_image).limit(1).to_pydantic(Images)[0]\nprint(actual.label == \"dog\")\n\nother = (\n    table.search(query_image, vector_column_name=\"vec_from_bytes\")\n    .limit(1)\n    .to_pydantic(Images)[0]\n)\nprint(other.label)\n";

export const PyEmbeddingOpenclipSetup = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport pandas as pd\nimport requests\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"openclip-demo\"))\nfunc = get_registry().get(\"open-clip\").create()\n\nclass Images(LanceModel):\n    label: str\n    image_uri: str = func.SourceField()\n    image_bytes: bytes = func.SourceField()\n    vector: Vector(func.ndims()) = func.VectorField()\n    vec_from_bytes: Vector(func.ndims()) = func.VectorField()\n\ntable = db.create_table(\"images\", schema=Images)\nlabels = [\"cat\", \"cat\", \"dog\", \"dog\", \"horse\", \"horse\"]\nuris = [\n    \"http://farm1.staticflickr.com/53/167798175_7c7845bbbd_z.jpg\",\n    \"http://farm1.staticflickr.com/134/332220238_da527d8140_z.jpg\",\n    \"http://farm9.staticflickr.com/8387/8602747737_2e5c2a45d4_z.jpg\",\n    \"http://farm5.staticflickr.com/4092/5017326486_1f46057f5f_z.jpg\",\n    \"http://farm9.staticflickr.com/8216/8434969557_d37882c42d_z.jpg\",\n    \"http://farm6.staticflickr.com/5142/5835678453_4f3a4edb45_z.jpg\",\n]\nimage_bytes = [requests.get(uri).content for uri in uris]\ntable.add(\n    pd.DataFrame({\"label\": labels, \"image_uri\": uris, \"image_bytes\": image_bytes})\n)\n";

export const PyEmbeddingOpenclipTextSearch = "actual = table.search(\"man's best friend\").limit(1).to_pydantic(Images)[0]\nprint(actual.label)\n\nfrombytes = (\n    table.search(\"man's best friend\", vector_column_name=\"vec_from_bytes\")\n    .limit(1)\n    .to_pydantic(Images)[0]\n)\nprint(frombytes.label)\n";

export const PyEmbeddingSentenceTransformersBaai = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"sentence-transformers\"))\nmodel = (\n    get_registry()\n    .get(\"sentence-transformers\")\n    .create(name=\"BAAI/bge-small-en-v1.5\", device=\"cpu\")\n)\n\nclass Words(LanceModel):\n    text: str = model.SourceField()\n    vector: Vector(model.ndims()) = model.VectorField()\n\ntable = db.create_table(\"words\", schema=Words)\ntable.add(\n    [\n        {\"text\": \"hello world\"},\n        {\"text\": \"goodbye world\"},\n    ]\n)\n\nquery = \"greetings\"\nactual = table.search(query).limit(1).to_pydantic(Words)[0]\nprint(actual.text)\n";

export const PyEmbeddingVoyageaiMultimodal = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import EmbeddingFunctionRegistry\nfrom lancedb.pydantic import LanceModel, Vector\n\n# Create multimodal embedding function with custom dimension\nvoyageai = (\n    EmbeddingFunctionRegistry.get_instance()\n    .get(\"voyageai\")\n    .create(name=\"voyage-multimodal-3.5\", output_dimension=512)\n)\n\nclass ImageModel(LanceModel):\n    image_uri: str = voyageai.SourceField()\n    vector: Vector(voyageai.ndims()) = voyageai.VectorField()\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"voyageai-multimodal\"))\ntbl = db.create_table(\"images\", schema=ImageModel, mode=\"overwrite\")\n\n# Add images using URLs\ntbl.add(\n    [\n        {\"image_uri\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/PNG_transparency_demonstration_1.png/300px-PNG_transparency_demonstration_1.png\"},\n    ]\n)\n\n# Search with text query\nresults = tbl.search(\"dice\").limit(1).to_list()\nprint(results)\n";

export const PyEmbeddingVoyageaiUsage = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.embeddings import EmbeddingFunctionRegistry\nfrom lancedb.pydantic import LanceModel, Vector\n\nvoyageai = (\n    EmbeddingFunctionRegistry.get_instance().get(\"voyageai\").create(name=\"voyage-3\")\n)\n\nclass TextModel(LanceModel):\n    text: str = voyageai.SourceField()\n    vector: Vector(voyageai.ndims()) = voyageai.VectorField()\n\ndata = [{\"text\": \"hello world\"}, {\"text\": \"goodbye world\"}]\n\ndb = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"voyageai-demo\"))\ntbl = db.create_table(\"test\", schema=TextModel, mode=\"overwrite\")\n\ntbl.add(data)\n";

export const PyFrameworksLangchainAddImages = "image_uris = [\"./assets/image-1.png\", \"./assets/image-2.png\"]\nvector_store.add_images(uris=image_uris)\n# here image_uris are local fs paths to the images.\n";

export const PyFrameworksLangchainAddTexts = "vector_store.add_texts(texts=[\"test_123\"], metadatas=[{\"source\": \"wiki\"}])\n\n# Additionaly, to explore the table you can load it into a df or save it in a csv file:\n\ntbl = vector_store.get_table()\nprint(\"tbl:\", tbl)\npd_df = tbl.to_pandas()\npd_df.to_csv(\"docsearch.csv\", index=False)\n\n# you can also create a new vector store object using an older connection object:\nvector_store = LanceDB(connection=tbl, embedding=embeddings)\n";

export const PyFrameworksLangchainCreateIndex = "# for creating vector index\nvector_store.create_index(vector_col=\"vector\", metric=\"cosine\")\n\n# for creating scalar index(for non-vector columns)\nvector_store.create_index(col_name=\"text\")\n";

export const PyFrameworksLangchainMaxMarginalRelevance = "result = docsearch.max_marginal_relevance_search(query=\"text\")\nresult_texts = [doc.page_content for doc in result]\nprint(result_texts)\n\n# search by vector :\nresult = docsearch.max_marginal_relevance_search_by_vector(\n    embeddings.embed_query(\"text\")\n)\nresult_texts = [doc.page_content for doc in result]\nprint(result_texts)\n";

export const PyFrameworksLangchainQuickStart = "import os\n\nfrom langchain.document_loaders import TextLoader\nfrom langchain.vectorstores import LanceDB\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n\nloader = TextLoader(\n    \"../../modules/state_of_the_union.txt\"\n)  # Replace with your data path\ndocuments = loader.load()\n\ndocuments = CharacterTextSplitter().split_documents(documents)\nembeddings = OpenAIEmbeddings()\n\ndocsearch = LanceDB.from_documents(documents, embeddings)\nquery = \"What did the president say about Ketanji Brown Jackson\"\ndocs = docsearch.similarity_search(query)\nprint(docs[0].page_content)\n";

export const PyFrameworksLangchainSimilaritySearch = "docs = docsearch.similarity_search(query)\nprint(docs[0].page_content)\n";

export const PyFrameworksLangchainSimilaritySearchByVector = "docs = docsearch.similarity_search_by_vector(query)\nprint(docs[0].page_content)\n";

export const PyFrameworksLangchainSimilaritySearchByVectorWithScores = "query_embedding = embeddings.embed_query(\"text\")\ndocs = docsearch.similarity_search_by_vector_with_relevance_scores(query_embedding)\nprint(\"relevance score - \", docs[0][1])\nprint(\"text- \", docs[0][0].page_content[:1000])\n";

export const PyFrameworksLangchainSimilaritySearchWithScores = "docs = docsearch.similarity_search_with_relevance_scores(query)\nprint(\"relevance score - \", docs[0][1])\nprint(\"text- \", docs[0][0].page_content[:1000])\n";

export const PyFrameworksLangchainVectorStoreConfig = "db_url = \"db://lang_test\"  # url of db you created\napi_key = \"xxxxx\"  # your API key\nregion = \"us-east-1-dev\"  # your selected region\n\nvector_store = LanceDB(\n    uri=db_url,\n    api_key=api_key,  # (dont include for local API)\n    region=region,  # (dont include for local API)\n    embedding=embeddings,\n    table_name=\"langchain_test\",  # Optional\n)\n";

export const PyFrameworksLlamaindexAddReranker = "from lancedb.rerankers import ColbertReranker\n\nreranker = ColbertReranker()\nvector_store._add_reranker(reranker)\n";

export const PyFrameworksLlamaindexFiltering = "from llama_index.core.vector_stores import (\n    FilterCondition,\n    FilterOperator,\n    MetadataFilter,\n    MetadataFilters,\n)\n\nquery_filters = MetadataFilters(\n    filters=[\n        MetadataFilter(\n            key=\"creation_date\", operator=FilterOperator.EQ, value=\"2024-05-23\"\n        ),\n        MetadataFilter(key=\"file_size\", value=75040, operator=FilterOperator.GT),\n    ],\n    condition=FilterCondition.AND,\n)\n";

export const PyFrameworksLlamaindexHybridSearch = "from lancedb.rerankers import ColbertReranker\n\nreranker = ColbertReranker()\nvector_store._add_reranker(reranker)\n\nquery_engine = index.as_query_engine(\n    filters=query_filters,\n    vector_store_kwargs={\n        \"query_type\": \"hybrid\",\n    },\n)\n\nresponse = query_engine.query(\"How much did Viaweb charge per month?\")\n";

export const PyFrameworksLlamaindexQuickStart = "import logging\nimport sys\nimport textwrap\n\nimport openai\n\n# Uncomment to see debug logs\n# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\nfrom llama_index.core import (\n    Document,\n    SimpleDirectoryReader,\n    StorageContext,\n    VectorStoreIndex,\n)\nfrom llama_index.vector_stores.lancedb import LanceDBVectorStore\n\nopenai.api_key = \"sk-...\"\n\ndocuments = SimpleDirectoryReader(\"./data/your-data-dir/\").load_data()\nprint(\"Document ID:\", documents[0].doc_id, \"Document Hash:\", documents[0].hash)\n\n## For LanceDB cloud :\n# vector_store = LanceDBVectorStore(\n#     uri=\"db://db_name\", # your remote DB URI\n#     api_key=\"sk_..\", # lancedb cloud api key\n#     region=\"your-region\" # the region you configured\n#     ...\n# )\n\nvector_store = LanceDBVectorStore(\n    uri=\"./lancedb\", mode=\"overwrite\", query_type=\"vector\"\n)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\nindex = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\nlance_filter = \"metadata.file_name = 'paul_graham_essay.txt' \"\nretriever = index.as_retriever(vector_store_kwargs={\"where\": lance_filter})\nresponse = retriever.retrieve(\"What did the author do growing up?\")\n";

export const PyFrameworksPydanticBaseExample = "table = db.create_table(\"docs\", schema=LanceDocs, mode=\"overwrite\")\ntable.add(\n    [\n        {\"text\": \"hello world\", \"vector\": [1.0, 0.0]},\n        {\"text\": \"goodbye world\", \"vector\": [0.0, 1.0]},\n    ]\n)\nresults = table.search(\"hello world\").limit(1).to_pydantic(LanceDocs)\nprint(results[0].text)\n";

export const PyFrameworksPydanticBaseModel = "class LanceDocs(LanceModel):\n    text: str\n    vector: Vector(2)\n";

export const PyFrameworksPydanticImports = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nfrom lancedb.pydantic import LanceModel, Vector\n";

export const PyFrameworksPydanticSetUrl = "db = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"pydantic-docs\"))\n";

export const PyFrameworksPydanticTypeConversion = "from typing import List, Optional\n\nimport pyarrow as pa\nimport pydantic\nfrom lancedb.pydantic import Vector, pydantic_to_schema\n\nclass FooModel(pydantic.BaseModel):\n    id: int\n    s: str\n    vec: Vector(1536)  # fixed_size_list<item: float32>[1536]\n    li: List[int]\n\nschema = pydantic_to_schema(FooModel)\nassert schema == pa.schema(\n    [\n        pa.field(\"id\", pa.int64(), False),\n        pa.field(\"s\", pa.utf8(), False),\n        pa.field(\"vec\", pa.list_(pa.float32(), 1536)),\n        pa.field(\"li\", pa.list_(pa.int64()), False),\n    ]\n)\n";

export const PyFrameworksPydanticVectorField = "import pyarrow as pa\nimport pydantic\nfrom lancedb.pydantic import Vector, pydantic_to_schema\n\nclass MyModel(pydantic.BaseModel):\n    id: int\n    url: str\n    embeddings: Vector(768)\n\nschema = pydantic_to_schema(MyModel)\nassert schema == pa.schema(\n    [\n        pa.field(\"id\", pa.int64(), False),\n        pa.field(\"url\", pa.utf8(), False),\n        pa.field(\"embeddings\", pa.list_(pa.float32(), 768)),\n    ]\n)\n";

export const PyPlatformsDltAdapterImport = "from dlt.destinations.adapters import lancedb_adapter\n";

export const PyPlatformsDltAdapterUsage = "load_info = pipeline.run(\n    lancedb_adapter(\n        movies_source,\n        embed=\"Title\",\n    )\n)\n";

export const PyPlatformsDltPipeline = "# Import necessary modules\nimport dlt\nfrom rest_api import rest_api_source\n\n# Configure the REST API source\nmovies_source = rest_api_source(\n    {\n        \"client\": {\n            \"base_url\": \"https://www.omdbapi.com/\",\n            \"auth\": {  # authentication strategy for the OMDb API\n                \"type\": \"api_key\",\n                \"name\": \"apikey\",\n                \"api_key\": dlt.secrets[\n                    \"sources.rest_api.api_token\"\n                ],  # read API credentials directly from secrets.toml\n                \"location\": \"query\",\n            },\n            \"paginator\": {  # pagination strategy for the OMDb API\n                \"type\": \"page_number\",\n                \"base_page\": 1,\n                \"total_path\": \"totalResults\",\n                \"maximum_page\": 5,\n            },\n        },\n        \"resources\": [  # list of API endpoints to request\n            {\n                \"name\": \"movie_search\",\n                \"endpoint\": {\n                    \"path\": \"/\",\n                    \"params\": {\n                        \"s\": \"godzilla\",\n                        \"type\": \"movie\",\n                    },\n                },\n            }\n        ],\n    }\n)\n\nif __name__ == \"__main__\":\n    # Create a pipeline object\n    pipeline = dlt.pipeline(\n        pipeline_name=\"movies_pipeline\",\n        destination=\"lancedb\",  # this tells dlt to load the data into LanceDB\n        dataset_name=\"movies_data_pipeline\",\n    )\n\n    # Run the pipeline\n    load_info = pipeline.run(movies_source)\n\n    # pretty print the information on data that was loaded\n    print(load_info)\n";

export const PyPlatformsDuckdbCreateTable = "import lancedb\n\ndb = lancedb.connect(\"data/sample-lancedb\")\ndata = [\n    {\"vector\": [3.1, 4.1], \"item\": \"foo\", \"price\": 10.0},\n    {\"vector\": [5.9, 26.5], \"item\": \"bar\", \"price\": 20.0},\n]\ntable = db.create_table(\"pd_table\", data=data)\n";

export const PyPlatformsDuckdbMeanPrice = "duckdb.query(\"SELECT mean(price) FROM arrow_table\")\n";

export const PyPlatformsDuckdbQueryTable = "import duckdb\n\narrow_table = table.to_lance()\n\nduckdb.query(\"SELECT * FROM arrow_table\")\n";

export const PyPlatformsPandasAsyncExample = "async def run_pandas_async_example() -> None:\n    async_db = await lancedb.connect_async(\n        str(Path(tempfile.mkdtemp()) / \"pandas-async\")\n    )\n    async_df = pd.DataFrame(\n        [\n            {\"id\": \"10\", \"text\": \"sage\", \"vector\": [0.6, 0.4, 0.8]},\n            {\"id\": \"11\", \"text\": \"bard\", \"vector\": [0.2, 0.7, 0.3]},\n        ]\n    )\n    async_table = await async_db.create_table(\n        \"creatures_async\", data=async_df, mode=\"overwrite\"\n    )\n    async_results = await (\n        async_table.search([0.6, 0.4, 0.8])\n        .select([\"text\", \"_distance\"])\n        .limit(1)\n        .to_pandas()\n    )\n    print(async_results)\n\nasyncio.run(run_pandas_async_example())\n";

export const PyPlatformsPandasCreateTable = "pandas_df = pd.DataFrame(\n    [\n        {\"id\": \"1\", \"text\": \"dragon\", \"vector\": [0.9, 0.1, 0.3]},\n        {\"id\": \"2\", \"text\": \"griffin\", \"vector\": [0.4, 0.5, 0.2]},\n        {\"id\": \"3\", \"text\": \"phoenix\", \"vector\": [0.7, 0.3, 0.6]},\n    ]\n)\npandas_db = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"pandas-demo\"))\npandas_table = pandas_db.create_table(\"creatures\", data=pandas_df, mode=\"overwrite\")\n";

export const PyPlatformsPandasImports = "import asyncio\nimport tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport pandas as pd\n";

export const PyPlatformsPandasVectorSearch = "pandas_results = (\n    pandas_table.search([0.9, 0.1, 0.3])\n    .select([\"text\", \"_distance\"])\n    .limit(1)\n    .to_pandas()\n)\nprint(pandas_results)\n";

export const PyPlatformsPhidataCliChat = "assistant.print_response(\"Ask me about something from the knowledge base\")\nwhile True:\n    message = Prompt.ask(f\"[bold] :sunglasses: User [/bold]\")\n    if message in (\"exit\", \"bye\"):\n        break\n    assistant.print_response(message, markdown=True)\n";

export const PyPlatformsPhidataDocumentModel = "from typing import Any, Dict, List, Optional\n\nfrom pydantic import BaseModel\n\nclass Document(BaseModel):\n    \"\"\"Model for managing a document\"\"\"\n\n    content: str  # <--- here data of chunk is stored\n    id: Optional[str] = None\n    name: Optional[str] = None\n    meta_data: Dict[str, Any] = {}\n    embedder: Optional[\"Embedder\"] = None\n    embedding: Optional[List[float]] = None\n    usage: Optional[Dict[str, Any]] = None\n";

export const PyPlatformsPhidataLoadKnowledgeBase = "assistant.knowledge_base.load(recreate=False)\n";

export const PyPlatformsPhidataOllamaAssistant = "# define an assistant with llama3.1 llm and reference to the knowledge base created above\nassistant = Assistant(\n    llm=Ollama(model=\"llama3.1\"),\n    description=\"\"\"You are an Expert in explaining youtube video transcripts. You are a bot that takes transcript of a video and answer the question based on it.\n\n    This is transcript for the above timestamp: {relevant_document}\n    The user input is: {user_input}\n    generate highlights only when asked.\n    When asked to generate highlights from the video, understand the context for each timestamp and create key highlight points, answer in following way -\n    [timestamp] - highlight 1\n    [timestamp] - highlight 2\n    ... so on\n\n    Your task is to understand the user question, and provide an answer using the provided contexts. Your answers are correct, high-quality, and written by an domain expert. If the provided context does not contain the answer, simply state,'The provided context does not have the answer.'\"\"\",\n    knowledge_base=knowledge_base,\n    add_references_to_prompt=True,\n)\n";

export const PyPlatformsPhidataOllamaKnowledgeBase = "# Create knowledge Base with OllamaEmbedder in LanceDB\nknowledge_base = TextKnowledgeBase(\n    path=\"transcript.txt\",\n    vector_db=LanceDb(\n        embedder=OllamaEmbedder(model=\"nomic-embed-text\", dimensions=768),\n        table_name=\"transcript_documents\",\n        uri=\"./t2mp/.lancedb\",\n    ),\n    num_documents=10,\n)\n";

export const PyPlatformsPhidataOllamaSetup = "from phi.assistant import Assistant\nfrom phi.embedder.ollama import OllamaEmbedder\nfrom phi.knowledge.text import TextKnowledgeBase\nfrom phi.llm.ollama import Ollama\nfrom phi.vectordb.lancedb import LanceDb\nfrom rich.prompt import Prompt\nfrom transcript import extract_transcript\n\n# The code below creates a file \"transcript.txt\" in the directory, the txt file will be used below\nyoutube_url = \"https://www.youtube.com/watch?v=Xs33-Gzl8Mo\"\nsegment_duration = 20\ntranscript_text, dict_transcript = extract_transcript(youtube_url, segment_duration)\n";

export const PyPlatformsPhidataOpenaiAssistant = "# define an assistant with gpt-4o-mini llm and reference to the knowledge base created above\nassistant = Assistant(\n    llm=OpenAIChat(\n        model=\"gpt-4o-mini\",\n        max_tokens=1000,\n        temperature=0.3,\n        api_key=openai.api_key,\n    ),\n    description=\"\"\"You are an Expert in explaining youtube video transcripts. You are a bot that takes transcript of a video and answer the question based on it.\n\n    This is transcript for the above timestamp: {relevant_document}\n    The user input is: {user_input}\n    generate highlights only when asked.\n    When asked to generate highlights from the video, understand the context for each timestamp and create key highlight points, answer in following way -\n    [timestamp] - highlight 1\n    [timestamp] - highlight 2\n    ... so on\n\n    Your task is to understand the user question, and provide an answer using the provided contexts. Your answers are correct, high-quality, and written by an domain expert. If the provided context does not contain the answer, simply state,'The provided context does not have the answer.'\"\"\",\n    knowledge_base=knowledge_base,\n    add_references_to_prompt=True,\n)\n";

export const PyPlatformsPhidataOpenaiKnowledgeBase = "# Create knowledge Base with OpenAIEmbedder in LanceDB\nknowledge_base = TextKnowledgeBase(\n    path=\"transcript.txt\",\n    vector_db=LanceDb(\n        embedder=OpenAIEmbedder(api_key=openai.api_key),\n        table_name=\"transcript_documents\",\n        uri=\"./t3mp/.lancedb\",\n    ),\n    num_documents=10,\n)\n";

export const PyPlatformsPhidataOpenaiSetup = "import os\n\nimport openai\nfrom phi.assistant import Assistant\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.text import TextKnowledgeBase\nfrom phi.llm.openai import OpenAIChat\nfrom phi.vectordb.lancedb import LanceDb\nfrom rich.prompt import Prompt\nfrom transcript import extract_transcript\n\nif \"OPENAI_API_KEY\" not in os.environ:\n    # OR set the key here as a variable\n    openai.api_key = \"sk-...\"\n\n# The code below creates a file \"transcript.txt\" in the directory, the txt file will be used below\nyoutube_url = \"https://www.youtube.com/watch?v=Xs33-Gzl8Mo\"\nsegment_duration = 20\ntranscript_text, dict_transcript = extract_transcript(youtube_url, segment_duration)\n";

export const PyPlatformsPhidataTranscriptModule = "import re\n\nfrom youtube_transcript_api import YouTubeTranscriptApi\n\ndef smodify(seconds):\n    hours, remainder = divmod(seconds, 3600)\n    minutes, seconds = divmod(remainder, 60)\n    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n\ndef extract_transcript(youtube_url, segment_duration):\n    # Extract video ID from the URL\n    video_id = re.search(r\"(?<=v=)[\\w-]+\", youtube_url)\n    if not video_id:\n        video_id = re.search(r\"(?<=be/)[\\w-]+\", youtube_url)\n    if not video_id:\n        return None\n\n    video_id = video_id.group(0)\n\n    # Attempt to fetch the transcript\n    try:\n        # Try to get the official transcript\n        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n    except Exception:\n        # If no official transcript is found, try to get auto-generated transcript\n        try:\n            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n            for transcript in transcript_list:\n                transcript = transcript.translate(\"en\").fetch()\n        except Exception:\n            return None\n\n    # Format the transcript into 120s chunks\n    transcript_text, dict_transcript = format_transcript(\n        transcript, segment_duration\n    )\n    # Open the file in write mode, which creates it if it doesn't exist\n    with open(\"transcript.txt\", \"w\", encoding=\"utf-8\") as file:\n        file.write(transcript_text)\n    return transcript_text, dict_transcript\n\ndef format_transcript(transcript, segment_duration):\n    chunked_transcript = []\n    chunk_dict = []\n    current_chunk = []\n    current_time = 0\n    # 2 minutes in seconds\n    start_time_chunk = 0  # To track the start time of the current chunk\n\n    for segment in transcript:\n        start_time = segment[\"start\"]\n        end_time_x = start_time + segment[\"duration\"]\n        text = segment[\"text\"]\n\n        # Add text to the current chunk\n        current_chunk.append(text)\n\n        # Update the current time with the duration of the current segment\n        # The duration of the current segment is given by segment['start'] - start_time_chunk\n        if current_chunk:\n            current_time = start_time - start_time_chunk\n\n        # If current chunk duration reaches or exceeds 2 minutes, save the chunk\n        if current_time >= segment_duration:\n            # Use the start time of the first segment in the current chunk as the timestamp\n            chunked_transcript.append(\n                f\"[{smodify(start_time_chunk)} to {smodify(end_time_x)}] \"\n                + \" \".join(current_chunk)\n            )\n            current_chunk = re.sub(\n                r\"[\\xa0\\n]\",\n                lambda x: \"\" if x.group() == \"\\xa0\" else \" \",\n                \"\\n\".join(current_chunk),\n            )\n            chunk_dict.append(\n                {\n                    \"timestamp\": f\"[{smodify(start_time_chunk)} to {smodify(end_time_x)}]\",\n                    \"text\": \"\".join(current_chunk),\n                }\n            )\n            current_chunk = []  # Reset the chunk\n            start_time_chunk = (\n                start_time + segment[\"duration\"]\n            )  # Update the start time for the next chunk\n            current_time = 0  # Reset current time\n\n    # Add any remaining text in the last chunk\n    if current_chunk:\n        chunked_transcript.append(\n            f\"[{smodify(start_time_chunk)} to {smodify(end_time_x)}] \"\n            + \" \".join(current_chunk)\n        )\n        current_chunk = re.sub(\n            r\"[\\xa0\\n]\",\n            lambda x: \"\" if x.group() == \"\\xa0\" else \" \",\n            \"\\n\".join(current_chunk),\n        )\n        chunk_dict.append(\n            {\n                \"timestamp\": f\"[{smodify(start_time_chunk)} to {smodify(end_time_x)}]\",\n                \"text\": \"\".join(current_chunk),\n            }\n        )\n\n    return \"\\n\\n\".join(chunked_transcript), chunk_dict\n";

export const PyPlatformsPolarsCreateTable = "birds = pl.DataFrame(\n    {\n        \"text\": [\"phoenix\", \"sparrow\"],\n        \"vector\": [\n            [0.1, 0.2, 0.3],\n            [0.8, 0.6, 0.5],\n        ],\n    }\n)\npolars_db = lancedb.connect(str(Path(tempfile.mkdtemp()) / \"polars-demo\"))\npolars_table = polars_db.create_table(\n    \"birds\", data=birds.to_arrow(), mode=\"overwrite\"\n)\n";

export const PyPlatformsPolarsImports = "import tempfile\nfrom pathlib import Path\n\nimport lancedb\nimport polars as pl\nfrom lancedb.pydantic import LanceModel, Vector\n";

export const PyPlatformsPolarsLazyframe = "lazy_frame = polars_table.to_polars().lazy()\nprint(lazy_frame.select([\"text\"]).collect())\n";

export const PyPlatformsPolarsPydantic = "class BirdModel(LanceModel):\n    text: str\n    vector: Vector(3)\n\nschema_table = polars_db.create_table(\n    \"birds_schema\", schema=BirdModel, mode=\"overwrite\"\n)\nschema_table.add(birds.to_dicts())\n";

export const PyPlatformsPolarsVectorSearch = "polars_results = (\n    polars_table.search([0.1, 0.2, 0.3])\n    .select([\"text\", \"_distance\"])\n    .limit(1)\n    .to_polars()\n)\nprint(polars_results)\n";

export const PyPlatformsVoxel51BackendFlag = "import fiftyone.brain as fob\n\n# Re-run similarity creation using the LanceDB backend explicitly\nfob.compute_similarity(\n    dataset,\n    model=\"clip-vit-base32-torch\",\n    brain_key=\"lancedb_index\",\n    backend=\"lancedb\",\n)\n";

export const PyPlatformsVoxel51BackendParams = "lancedb_index = fob.compute_similarity(\n    dataset,\n    model=\"clip-vit-base32-torch\",\n    backend=\"lancedb\",\n    brain_key=\"lancedb_index\",\n    table_name=\"your-table\",\n    metric=\"euclidean\",\n    uri=\"/tmp/lancedb\",\n)\n";

export const PyPlatformsVoxel51BrainConfig = "import fiftyone.brain as fob\n\n# Print your current brain config\nprint(fob.brain_config)\n";

export const PyPlatformsVoxel51Cleanup = "# Step 5 (optional): Cleanup\n\n# Delete the LanceDB table\nlancedb_index.cleanup()\n\n# Delete run record from FiftyOne\ndataset.delete_brain_run(\"lancedb_index\")\n";

export const PyPlatformsVoxel51ComputeSimilarity = "# Steps 2 and 3: Compute embeddings and create a similarity index\nlancedb_index = fob.compute_similarity(\n    dataset,\n    model=\"clip-vit-base32-torch\",\n    brain_key=\"lancedb_index\",\n    backend=\"lancedb\",\n)\n";

export const PyPlatformsVoxel51LoadDataset = "import fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\n\n# Step 1: Load your data into FiftyOne\ndataset = foz.load_zoo_dataset(\"quickstart\")\n";

export const PyPlatformsVoxel51SortBySimilarity = "# Step 4: Query your data\nquery = dataset.first().id  # query by sample ID\nview = dataset.sort_by_similarity(\n    query,\n    brain_key=\"lancedb_index\",\n    k=10,  # limit to 10 most similar samples\n)\n";

export const PyRerankingAnswerdotaiUsage = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import AnswerdotaiRerankers\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = AnswerdotaiRerankers()\n\n# Run vector search with a reranker\nresult = tbl.search(\"hello\").rerank(reranker=reranker).to_list()\n\n# Run FTS search with a reranker\nresult = tbl.search(\"hello\", query_type=\"fts\").rerank(reranker=reranker).to_list()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingCohereUsage = "import os\n\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import CohereReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = CohereReranker(api_key=os.environ[\"COHERE_API_KEY\"])\n\n# Run vector search with a reranker\nresult = tbl.search(\"hello\").rerank(reranker=reranker).to_list()\n\n# Run FTS search with a reranker\nresult = tbl.search(\"hello\", query_type=\"fts\").rerank(reranker=reranker).to_list()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingColbertUsage = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import ColbertReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = ColbertReranker()\n\n# Run vector search with a reranker\nresult = tbl.search(\"hello\").rerank(reranker=reranker).to_list()\n\n# Run FTS search with a reranker\nresult = tbl.search(\"hello\", query_type=\"fts\").rerank(reranker=reranker).to_list()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingCrossEncoderUsage = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import CrossEncoderReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = CrossEncoderReranker()\n\n# Run vector search with a reranker\nresult = tbl.search(\"hello\").rerank(reranker=reranker).to_list()\n\n# Run FTS search with a reranker\nresult = tbl.search(\"hello\", query_type=\"fts\").rerank(reranker=reranker).to_list()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingJinaUsage = "import os\n\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import JinaReranker\n\nembedder = get_registry().get(\"jina\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = JinaReranker(api_key=os.environ[\"JINA_API_KEY\"])\n\n# Run vector search with a reranker\nresult = tbl.search(\"hello\").rerank(reranker=reranker).to_list()\n\n# Run FTS search with a reranker\nresult = tbl.search(\"hello\", query_type=\"fts\").rerank(reranker=reranker).to_list()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingLinearCombinationUsage = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import LinearCombinationReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = LinearCombinationReranker()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingMrrMultivector = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import MRRReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    meta: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n    meta_vector: Vector(embedder.ndims()) = embedder.VectorField(source_column=\"meta\")\n\ndata = [\n    {\"text\": \"hello world\", \"meta\": \"greeting message\"},\n    {\"text\": \"goodbye world\", \"meta\": \"farewell message\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\n\n# Search across multiple vector columns and collect results with row IDs\nquery = \"hello\"\nrs1 = tbl.search(query, vector_column_name=\"vector\").limit(10).with_row_id(True).to_arrow()\nrs2 = tbl.search(query, vector_column_name=\"meta_vector\").limit(10).with_row_id(True).to_arrow()\n\n# Rerank the combined results using MRR\nreranker = MRRReranker()\ncombined_results = reranker.rerank_multivector([rs1, rs2])\n";

export const PyRerankingMrrUsage = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import MRRReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = MRRReranker(weight_vector=0.7, weight_fts=0.3)\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n\n# Run multivector search across multiple vector columns\nrs1 = tbl.search(\"hello\").limit(10).with_row_id(True).to_arrow()\nrs2 = tbl.search(\"greeting\").limit(10).with_row_id(True).to_arrow()\ncombined = MRRReranker().rerank_multivector([rs1, rs2])\n";

export const PyRerankingOpenaiUsage = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import OpenaiReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = OpenaiReranker()\n\n# Run vector search with a reranker\nresult = tbl.search(\"hello\").rerank(reranker=reranker).to_list()\n\n# Run FTS search with a reranker\nresult = tbl.search(\"hello\", query_type=\"fts\").rerank(reranker=reranker).to_list()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingRrfUsage = "import lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import RRFReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = RRFReranker()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const PyRerankingVoyageaiUsage = "import os\n\nimport lancedb\nfrom lancedb.embeddings import get_registry\nfrom lancedb.pydantic import LanceModel, Vector\nfrom lancedb.rerankers import VoyageAIReranker\n\nembedder = get_registry().get(\"sentence-transformers\").create()\ndb = lancedb.connect(\"~/.lancedb\")\n\nclass Schema(LanceModel):\n    text: str = embedder.SourceField()\n    vector: Vector(embedder.ndims()) = embedder.VectorField()\n\ndata = [\n    {\"text\": \"hello world\"},\n    {\"text\": \"goodbye world\"},\n]\ntbl = db.create_table(\"test\", schema=Schema, mode=\"overwrite\")\ntbl.add(data)\nreranker = VoyageAIReranker(model_name=\"rerank-2\")\n\n# Run vector search with a reranker\nresult = tbl.search(\"hello\").rerank(reranker=reranker).to_list()\n\n# Run FTS search with a reranker\nresult = tbl.search(\"hello\", query_type=\"fts\").rerank(reranker=reranker).to_list()\n\n# Run hybrid search with a reranker\ntbl.create_fts_index(\"text\", replace=True)\nresult = (\n    tbl.search(\"hello\", query_type=\"hybrid\").rerank(reranker=reranker).to_list()\n)\n";

export const TsFrameworksGenkitCustomIndexer = "export const menuPdfIndexer = lancedbIndexerRef({\n  // Using all defaults, for dbUri, tableName, and embedder, etc\n});\n\nconst chunkingConfig = {\n  minLength: 1000,\n  maxLength: 2000,\n  splitter: \"sentence\",\n  overlap: 100,\n  delimiters: \"\",\n} as any;\n\nasync function extractTextFromPdf(filePath: string) {\n  const pdfFile = path.resolve(filePath);\n  const dataBuffer = await readFile(pdfFile);\n  const data = await pdf(dataBuffer);\n  return data.text;\n}\n\nexport const indexMenu = ai.defineFlow(\n  {\n    name: \"indexMenu\",\n    inputSchema: z.string().describe(\"PDF file path\"),\n    outputSchema: z.void(),\n  },\n  async (filePath: string) => {\n    filePath = path.resolve(filePath);\n\n    // Read the pdf.\n    const pdfTxt = await ai.run(\"extract-text\", () => extractTextFromPdf(filePath));\n\n    // Divide the pdf text into segments.\n    const chunks = await ai.run(\"chunk-it\", async () => chunk(pdfTxt, chunkingConfig));\n\n    // Convert chunks of text into documents to store in the index.\n    const documents = chunks.map((text) => {\n      return Document.fromText(text, { filePath });\n    });\n\n    // Add documents to the index.\n    await ai.index({\n      indexer: menuPdfIndexer,\n      documents,\n      options: {\n        writeMode: WriteMode.Overwrite,\n      } as any,\n    });\n  },\n);\n";

export const TsFrameworksGenkitCustomRetriever = "export const menuRetriever = lancedbRetrieverRef({\n  tableName: \"table\", // Use the same table name as the indexer.\n  displayName: \"Menu\", // Use a custom display name.\n});\n\nexport const menuQAFlow = ai.defineFlow(\n  { name: \"Menu\", inputSchema: z.string(), outputSchema: z.string() },\n  async (input: string) => {\n    // retrieve relevant documents\n    const docs = await ai.retrieve({\n      retriever: menuRetriever,\n      query: input,\n      options: {\n        k: 3,\n      },\n    });\n\n    const extractedContent = docs.map((doc) => {\n      if (doc.content && Array.isArray(doc.content) && doc.content.length > 0) {\n        if (doc.content[0].media && doc.content[0].media.url) {\n          return doc.content[0].media.url;\n        }\n      }\n      return \"No content found\";\n    });\n\n    console.log(\"Extracted content:\", extractedContent);\n\n    const { text } = await ai.generate({\n      model: gemini(\"gemini-2.0-flash\"),\n      prompt: `\nYou are acting as a helpful AI assistant that can answer \nquestions about the food available on the menu at Genkit Grub Pub.\n\nUse only the context provided to answer the question.\nIf you don't know, do not make up an answer.\nDo not add or change items on the menu.\n\nContext:\n${extractedContent.join(\"\\n\\n\")}\n\nQuestion: ${input}`,\n      docs,\n    });\n\n    return text;\n  },\n);\n";

export const TsFrameworksGenkitUsage = "import { lancedbIndexerRef, lancedb, lancedbRetrieverRef, WriteMode } from \"genkitx-lancedb\";\nimport { textEmbedding004, vertexAI } from \"@genkit-ai/vertexai\";\nimport { gemini } from \"@genkit-ai/vertexai\";\nimport { z, genkit } from \"genkit\";\nimport { Document } from \"genkit/retriever\";\nimport { chunk } from \"llm-chunk\";\nimport { readFile } from \"fs/promises\";\nimport path from \"path\";\nimport pdf from \"pdf-parse/lib/pdf-parse\";\n\nconst ai = genkit({\n  plugins: [\n    // vertexAI provides the textEmbedding004 embedder\n    vertexAI(),\n\n    // the local vector store requires an embedder to translate from text to vector\n    lancedb([\n      {\n        dbUri: \".db\", // optional lancedb uri, default to .db\n        tableName: \"table\", // optional table name, default to table\n        embedder: textEmbedding004,\n      },\n    ]),\n  ],\n});\n";

