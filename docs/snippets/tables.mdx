{/* Auto-generated by scripts/mdx_snippets_gen.py. Do not edit manually. */}

export const PyAddColumnsCalculated = "table_name = \"schema_evolution_add_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 2,\n        \"name\": \"Smartphone\",\n        \"price\": 800.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 3,\n        \"name\": \"Headphones\",\n        \"price\": 150.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 4,\n        \"name\": \"Monitor\",\n        \"price\": 350.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 5,\n        \"name\": \"Keyboard\",\n        \"price\": 80.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\n\ntable = db.create_table(table_name, data, mode=\"overwrite\")\n\n# Add a discounted price column (10% discount)\ntable.add_columns({\"discounted_price\": \"cast((price * 0.9) as float)\"})\n";

export const PyAddColumnsDefaultValues = "table_name = \"schema_evolution_add_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 2,\n        \"name\": \"Smartphone\",\n        \"price\": 800.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\ntable = db.create_table(table_name, data, mode=\"overwrite\")\n\n# Add a stock status column with default value\ntable.add_columns({\"in_stock\": \"cast(true as boolean)\"})\n";

export const PyAddColumnsNullable = "table_name = \"schema_evolution_add_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200.00,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\ntable = db.create_table(table_name, data, mode=\"overwrite\")\n\n# Add a nullable timestamp column\ntable.add_columns({\"last_ordered\": \"cast(NULL as timestamp)\"})\n";

export const PyAddDataNestedModel = "from lancedb.pydantic import LanceModel, Vector\nfrom pydantic import BaseModel\n\nclass Document(BaseModel):\n    content: str\n    source: str\n\nclass NestedSchema(LanceModel):\n    id: str\n    vector: Vector(128)\n    document: Document\n\n# Create table with nested schema\ntable_name = \"nested_model_example\"\ndb = tmp_db\ntable = db.create_table(table_name, schema=NestedSchema, mode=\"overwrite\")\n";

export const PyAddDataPydanticModel = "from lancedb.pydantic import LanceModel, Vector\n\n# Define a Pydantic model\nclass Content(LanceModel):\n    movie_id: int\n    vector: Vector(128)\n    genres: str\n    title: str\n    imdb_id: int\n\n    @property\n    def imdb_url(self) -> str:\n        return f\"https://www.imdb.com/title/tt{self.imdb_id}\"\n\n# Create table with Pydantic model schema\ntable_name = \"pydantic_example\"\ndb = tmp_db\ntable = db.create_table(table_name, schema=Content, mode=\"overwrite\")\n";

export const PyAddDataToTable = "import lancedb\nimport pyarrow as pa\n\n# create an empty table with schema\ndata = [\n    {\"vector\": [3.1, 4.1], \"item\": \"foo\", \"price\": 10.0},\n    {\"vector\": [5.9, 26.5], \"item\": \"bar\", \"price\": 20.0},\n    {\"vector\": [10.2, 100.8], \"item\": \"baz\", \"price\": 30.0},\n    {\"vector\": [1.4, 9.5], \"item\": \"fred\", \"price\": 40.0},\n]\n\nschema = pa.schema(\n    [\n        pa.field(\"vector\", pa.list_(pa.float32(), 2)),\n        pa.field(\"item\", pa.utf8()),\n        pa.field(\"price\", pa.float32()),\n    ]\n)\n\ntable_name = \"basic_ingestion_example\"\ndb = tmp_db\ntable = db.create_table(table_name, schema=schema, mode=\"overwrite\")\n# Add data\ntable.add(data)\n";

export const PyAlterColumnsDataType = "table_name = \"schema_evolution_alter_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200,\n        \"discount_price\": 1080.0,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\nschema = pa.schema(\n    {\n        \"id\": pa.int64(),\n        \"name\": pa.string(),\n        \"price\": pa.int32(),\n        \"discount_price\": pa.float64(),\n        \"vector\": pa.list_(pa.float32(), 128),\n    }\n)\n\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\n# Change price from int32 to int64 for larger numbers\ntable.alter_columns({\"path\": \"price\", \"data_type\": pa.int64()})\n";

export const PyAlterColumnsMultiple = "table_name = \"schema_evolution_alter_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200,\n        \"discount_price\": 1080.0,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\nschema = pa.schema(\n    {\n        \"id\": pa.int64(),\n        \"name\": pa.string(),\n        \"price\": pa.int32(),\n        \"discount_price\": pa.float64(),\n        \"vector\": pa.list_(pa.float32(), 128),\n    }\n)\n\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\ntable.alter_columns({\"path\": \"discount_price\", \"rename\": \"sale_price\"})\n\n# Rename, change type, and make nullable in one operation\ntable.alter_columns(\n    {\n        \"path\": \"sale_price\",\n        \"rename\": \"final_price\",\n        \"data_type\": pa.float64(),\n        \"nullable\": True,\n    }\n)\n";

export const PyAlterColumnsNullable = "table_name = \"schema_evolution_alter_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200,\n        \"discount_price\": 1080.0,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\nschema = pa.schema(\n    {\n        \"id\": pa.int64(),\n        \"name\": pa.string(),\n        \"price\": pa.int32(),\n        \"discount_price\": pa.float64(),\n        \"vector\": pa.list_(pa.float32(), 128),\n    }\n)\n\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\n# Make the name column nullable\ntable.alter_columns({\"path\": \"name\", \"nullable\": True})\n";

export const PyAlterColumnsRename = "table_name = \"schema_evolution_alter_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200,\n        \"discount_price\": 1080.0,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 2,\n        \"name\": \"Smartphone\",\n        \"price\": 800,\n        \"discount_price\": 720.0,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\nschema = pa.schema(\n    {\n        \"id\": pa.int64(),\n        \"name\": pa.string(),\n        \"price\": pa.int32(),\n        \"discount_price\": pa.float64(),\n        \"vector\": pa.list_(pa.float32(), 128),\n    }\n)\n\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\n# Rename discount_price to sale_price\ntable.alter_columns({\"path\": \"discount_price\", \"rename\": \"sale_price\"})\n";

export const PyAlterVectorColumn = "vector_dim = 768  # Your embedding dimension\ntable_name = \"vector_alter_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"embedding\": np.random.random(vector_dim).tolist(),\n    },\n]\ntable = db.create_table(table_name, data, mode=\"overwrite\")\n\ntable.alter_columns(\n    dict(path=\"embedding\", data_type=pa.list_(pa.float32(), vector_dim))\n)\n";

export const PyBatchDataInsertion = "import pyarrow as pa\n\ndef make_batches():\n    for i in range(5):  # Create 5 batches\n        yield pa.RecordBatch.from_arrays(\n            [\n                pa.array([[3.1, 4.1], [5.9, 26.5]], pa.list_(pa.float32(), 2)),\n                pa.array([f\"item{i*2+1}\", f\"item{i*2+2}\"]),\n                pa.array([float((i * 2 + 1) * 10), float((i * 2 + 2) * 10)]),\n            ],\n            [\"vector\", \"item\", \"price\"],\n        )\n\nschema = pa.schema(\n    [\n        pa.field(\"vector\", pa.list_(pa.float32(), 2)),\n        pa.field(\"item\", pa.utf8()),\n        pa.field(\"price\", pa.float32()),\n    ]\n)\n# Create table with batches\ntable_name = \"batch_ingestion_example\"\ndb = tmp_db\ntable = db.create_table(table_name, make_batches(), schema=schema, mode=\"overwrite\")\n";

export const PyConsistencyCheckoutLatest = "db = tmp_db\n# Create table first\ndata = [{\"vector\": [1.1, 1.2], \"lat\": 45.5}]\ntbl = db.create_table(\"test_table\", data, mode=\"overwrite\")\n\n# (Other writes happen to my_table from another process)\n\n# Check for updates\ntbl.checkout_latest()\n";

export const PyConsistencyEventual = "from datetime import timedelta\n\nuri = str(tmp_db.uri) if hasattr(tmp_db, \"uri\") else \"memory://\"\ndb = lancedb.connect(uri, read_consistency_interval=timedelta(seconds=5))\n# Create table first\ndata = [{\"vector\": [1.1, 1.2], \"lat\": 45.5}]\ndb.create_table(\"test_table\", data, mode=\"overwrite\")\ntbl = db.open_table(\"test_table\")\n";

export const PyConsistencyStrong = "from datetime import timedelta\n\nuri = str(tmp_db.uri) if hasattr(tmp_db, \"uri\") else \"memory://\"\ndb = lancedb.connect(uri, read_consistency_interval=timedelta(0))\n# Create table first\ndata = [{\"vector\": [1.1, 1.2], \"lat\": 45.5}]\ndb.create_table(\"test_table\", data, mode=\"overwrite\")\ntbl = db.open_table(\"test_table\")\n";

export const PyCreateEmptyTable = "import lancedb\nimport pyarrow as pa\n\nschema = pa.schema(\n    [\n        pa.field(\"vector\", pa.list_(pa.float32(), 2)),\n        pa.field(\"item\", pa.string()),\n        pa.field(\"price\", pa.float32()),\n    ]\n)\ndb = tmp_db\ntbl = db.create_table(\"test_empty_table\", schema=schema, mode=\"overwrite\")\n";

export const PyCreateEmptyTablePydantic = "import lancedb\nfrom lancedb.pydantic import LanceModel, Vector\n\nclass Item(LanceModel):\n    vector: Vector(2)\n    item: str\n    price: float\n\ndb = tmp_db\ntbl = db.create_table(\n    \"test_empty_table_new\", schema=Item.to_arrow_schema(), mode=\"overwrite\"\n)\n";

export const PyCreateTableCustomSchema = "import pyarrow as pa\n\ncustom_schema = pa.schema(\n    [\n        pa.field(\"vector\", pa.list_(pa.float32(), 4)),\n        pa.field(\"lat\", pa.float32()),\n        pa.field(\"long\", pa.float32()),\n    ]\n)\n\ndata = [\n    {\"vector\": [1.1, 1.2, 1.3, 1.4], \"lat\": 45.5, \"long\": -122.7},\n    {\"vector\": [0.2, 1.8, 0.4, 3.6], \"lat\": 40.1, \"long\": -74.1},\n]\ndb = tmp_db\ntbl = db.create_table(\n    \"my_table_custom_schema\", data, schema=custom_schema, mode=\"overwrite\"\n)\n";

export const PyCreateTableFromArrow = "import numpy as np\nimport pyarrow as pa\n\ndim = 16\ntotal = 2\nschema = pa.schema(\n    [pa.field(\"vector\", pa.list_(pa.float16(), dim)), pa.field(\"text\", pa.string())]\n)\ndata = pa.Table.from_arrays(\n    [\n        pa.array(\n            [np.random.randn(dim).astype(np.float16) for _ in range(total)],\n            pa.list_(pa.float16(), dim),\n        ),\n        pa.array([\"foo\", \"bar\"]),\n    ],\n    [\"vector\", \"text\"],\n)\ndb = tmp_db\ntbl = db.create_table(\"f16_tbl\", data, schema=schema, mode=\"overwrite\")\n";

export const PyCreateTableFromDicts = "data = [\n    {\"vector\": [1.1, 1.2], \"lat\": 45.5, \"long\": -122.7},\n    {\"vector\": [0.2, 1.8], \"lat\": 40.1, \"long\": -74.1},\n]\ndb = tmp_db\ndb.create_table(\"test_table\", data, mode=\"overwrite\")\ntbl = db[\"test_table\"]\ntbl.head()\n";

export const PyCreateTableFromIterator = "import pyarrow as pa\n\ndef make_batches():\n    for i in range(5):\n        yield pa.RecordBatch.from_arrays(\n            [\n                pa.array(\n                    [[3.1, 4.1, 5.1, 6.1], [5.9, 26.5, 4.7, 32.8]],\n                    pa.list_(pa.float32(), 4),\n                ),\n                pa.array([\"foo\", \"bar\"]),\n                pa.array([10.0, 20.0]),\n            ],\n            [\"vector\", \"item\", \"price\"],\n        )\n\nschema = pa.schema(\n    [\n        pa.field(\"vector\", pa.list_(pa.float32(), 4)),\n        pa.field(\"item\", pa.utf8()),\n        pa.field(\"price\", pa.float32()),\n    ]\n)\ndb = tmp_db\ndb.create_table(\"batched_tale\", make_batches(), schema=schema, mode=\"overwrite\")\n";

export const PyCreateTableFromPandas = "import pandas as pd\n\ndata = pd.DataFrame(\n    {\n        \"vector\": [[1.1, 1.2, 1.3, 1.4], [0.2, 1.8, 0.4, 3.6]],\n        \"lat\": [45.5, 40.1],\n        \"long\": [-122.7, -74.1],\n    }\n)\ndb = tmp_db\ndb.create_table(\"my_table_pandas\", data, mode=\"overwrite\")\ndb[\"my_table_pandas\"].head()\n";

export const PyCreateTableFromPolars = "import polars as pl\n\ndata = pl.DataFrame(\n    {\n        \"vector\": [[3.1, 4.1], [5.9, 26.5]],\n        \"item\": [\"foo\", \"bar\"],\n        \"price\": [10.0, 20.0],\n    }\n)\ndb = tmp_db\ntbl = db.create_table(\"my_table_pl\", data, mode=\"overwrite\")\n";

export const PyCreateTableFromPydantic = "from lancedb.pydantic import LanceModel, Vector\n\nclass Content(LanceModel):\n    movie_id: int\n    vector: Vector(128)\n    genres: str\n    title: str\n    imdb_id: int\n\n    @property\n    def imdb_url(self) -> str:\n        return f\"https://www.imdb.com/title/tt{self.imdb_id}\"\n\ndb = tmp_db\ntbl = db.create_table(\"movielens_small\", schema=Content, mode=\"overwrite\")\n";

export const PyCreateTableNestedSchema = "from lancedb.pydantic import LanceModel, Vector\n\n# --8<-- [start:tables_document_model]\nfrom pydantic import BaseModel\n\nclass Document(BaseModel):\n    content: str\n    source: str\n\n# --8<-- [end:tables_document_model]\n\nclass NestedSchema(LanceModel):\n    id: str\n    vector: Vector(1536)\n    document: Document\n\ndb = tmp_db\ntbl = db.create_table(\"nested_table\", schema=NestedSchema, mode=\"overwrite\")\n";

export const PyDeleteOperation = "db = tmp_db\n# Create table first\ndata = [\n    {\"vector\": [3.1, 4.1], \"item\": \"foo\", \"price\": 10.0},\n    {\"vector\": [5.9, 26.5], \"item\": \"bar\", \"price\": 20.0},\n    {\"vector\": [10.2, 100.8], \"item\": \"baz\", \"price\": 30.0},\n]\ntable = db.create_table(\"update_table_example\", data, mode=\"overwrite\")\n\n# delete data\npredicate = \"price = 30.0\"\ntable.delete(predicate)\n";

export const PyDropColumnsMultiple = "table_name = \"schema_evolution_drop_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200.00,\n        \"temp_col1\": \"X\",\n        \"temp_col2\": 100,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\n\ntable = db.create_table(table_name, data, mode=\"overwrite\")\n\n# Remove the second temporary column\ntable.drop_columns([\"temp_col2\"])\n";

export const PyDropColumnsSingle = "table_name = \"schema_evolution_drop_example\"\ndb = tmp_db\ndata = [\n    {\n        \"id\": 1,\n        \"name\": \"Laptop\",\n        \"price\": 1200.00,\n        \"temp_col1\": \"X\",\n        \"temp_col2\": 100,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 2,\n        \"name\": \"Smartphone\",\n        \"price\": 800.00,\n        \"temp_col1\": \"Y\",\n        \"temp_col2\": 200,\n        \"vector\": np.random.random(128).tolist(),\n    },\n    {\n        \"id\": 3,\n        \"name\": \"Headphones\",\n        \"price\": 150.00,\n        \"temp_col1\": \"Z\",\n        \"temp_col2\": 300,\n        \"vector\": np.random.random(128).tolist(),\n    },\n]\n\ntable = db.create_table(table_name, data, mode=\"overwrite\")\n\n# Remove the first temporary column\ntable.drop_columns([\"temp_col1\"])\n";

export const PyDropTable = "db = tmp_db\n# Create a table first\ndata = [{\"vector\": [1.1, 1.2], \"lat\": 45.5}]\ndb.create_table(\"my_table\", data, mode=\"overwrite\")\n\n# Drop the table\ndb.drop_table(\"my_table\")\n";

export const PyInsertIfNotExists = "# Create example table\ndb = tmp_db\ntable = db.create_table(\n    \"domains\",\n    [\n        {\"domain\": \"google.com\", \"name\": \"Google\"},\n        {\"domain\": \"github.com\", \"name\": \"GitHub\"},\n    ],\n    mode=\"overwrite\",\n)\n\n# Prepare new data - one existing and one new record\nnew_domains = [\n    {\"domain\": \"google.com\", \"name\": \"Google\"},\n    {\"domain\": \"facebook.com\", \"name\": \"Facebook\"},\n]\n\n# Insert only if domain doesn't exist\ntable.merge_insert(\"domain\").when_not_matched_insert_all().execute(new_domains)\n\n# Verify count - should be 3 (original 2 plus 1 new)\nprint(f\"Total domains: {table.count_rows()}\")  # 3\n";

export const PyOpenExistingTable = "db = tmp_db\n# Create a table first\ndata = [{\"vector\": [1.1, 1.2], \"lat\": 45.5, \"long\": -122.7}]\ndb.create_table(\"test_table\", data, mode=\"overwrite\")\n\n# List table names\nprint(db.table_names())\n\n# Open existing table\ntbl = db.open_table(\"test_table\")\n";

export const PyReplaceRangeOperation = "# Create example table with document chunks\ndb = tmp_db\ntable = db.create_table(\n    \"chunks\",\n    [\n        {\"doc_id\": 0, \"chunk_id\": 0, \"text\": \"Hello\"},\n        {\"doc_id\": 0, \"chunk_id\": 1, \"text\": \"World\"},\n        {\"doc_id\": 1, \"chunk_id\": 0, \"text\": \"Foo\"},\n        {\"doc_id\": 1, \"chunk_id\": 1, \"text\": \"Bar\"},\n        {\"doc_id\": 2, \"chunk_id\": 0, \"text\": \"Baz\"},\n    ],\n    mode=\"overwrite\",\n)\n\n# New data - replacing all chunks for doc_id 1 with just one chunk\nnew_chunks = [\n    {\"doc_id\": 1, \"chunk_id\": 0, \"text\": \"Zoo\"},\n]\n\n# Replace all chunks for doc_id 1\n(\n    table.merge_insert([\"doc_id\"])\n    .when_matched_update_all()\n    .when_not_matched_insert_all()\n    .when_not_matched_by_source_delete(\"doc_id = 1\")\n    .execute(new_chunks)\n)\n\n# Verify count for doc_id = 1 - should be 1\nprint(f\"Chunks for doc_id = 1: {table.count_rows('doc_id = 1')}\")  # 1\n";

export const PyTablesBasicConnect = "import lancedb\n\nuri = \"data/sample-lancedb\"\ndb = lancedb.connect(uri)\n";

export const PyTablesDocumentModel = "from pydantic import BaseModel\n\nclass Document(BaseModel):\n    content: str\n    source: str\n";

export const PyTablesImports = "import lancedb\nimport numpy as np\nimport pandas as pd\nimport pyarrow as pa\nimport pytest\nfrom numpy.random import randint, random\n";

export const PyTablesTzValidator = "from datetime import datetime\nfrom zoneinfo import ZoneInfo\n\nfrom lancedb.pydantic import LanceModel\nfrom pydantic import Field, ValidationError, ValidationInfo, field_validator\n\ntzname = \"America/New_York\"\ntz = ZoneInfo(tzname)\n\nclass TestModel(LanceModel):\n    dt_with_tz: datetime = Field(json_schema_extra={\"tz\": tzname})\n\n    @field_validator(\"dt_with_tz\")\n    @classmethod\n    def tz_must_match(cls, dt: datetime) -> datetime:\n        assert dt.tzinfo == tz\n        return dt\n\nok = TestModel(dt_with_tz=datetime.now(tz))\n\ntry:\n    TestModel(dt_with_tz=datetime.now(ZoneInfo(\"Asia/Shanghai\")))\n    assert 0 == 1, \"this should raise ValidationError\"\nexcept ValidationError:\n    print(\"A ValidationError was raised.\")\n    pass\n";

export const PyUpdateOperation = "import lancedb\nimport pandas as pd\n\n# Create a table from a pandas DataFrame\ndata = pd.DataFrame({\"x\": [1, 2, 3], \"vector\": [[1, 2], [3, 4], [5, 6]]})\ndb = tmp_db\ntbl = db.create_table(\"test_table\", data, mode=\"overwrite\")\n# Update the table where x = 2\ntbl.update(where=\"x = 2\", values={\"vector\": [10, 10]})\n# Get the updated table as a pandas DataFrame\ndf = tbl.to_pandas()\nprint(df)\n";

export const PyUpdateUsingSql = "import lancedb\nimport pandas as pd\n\n# Create a table from a pandas DataFrame\ndata = pd.DataFrame({\"x\": [1, 2, 3], \"vector\": [[1, 2], [3, 4], [5, 6]]})\ndb = tmp_db\ntbl = db.create_table(\"test_table\", data, mode=\"overwrite\")\n# Update the table where x = 2\ntbl.update(values_sql={\"x\": \"x + 1\"})\nprint(tbl.to_pandas())\n";

export const PyUpsertOperation = "# Create example table\nusers_table_name = \"users_example\"\ndb = tmp_db\ntable = db.create_table(\n    users_table_name,\n    [\n        {\"id\": 0, \"name\": \"Alice\"},\n        {\"id\": 1, \"name\": \"Bob\"},\n    ],\n    mode=\"overwrite\",\n)\nprint(f\"Created users table with {table.count_rows()} rows\")\n\n# Prepare data for upsert\nnew_users = [\n    {\"id\": 1, \"name\": \"Bobby\"},  # Will update existing record\n    {\"id\": 2, \"name\": \"Charlie\"},  # Will insert new record\n]\n\n# Upsert by id\n(\n    table.merge_insert(\"id\")\n    .when_matched_update_all()\n    .when_not_matched_insert_all()\n    .execute(new_users)\n)\n\n# Verify results - should be 3 records total\nprint(f\"Total users: {table.count_rows()}\")  # 3\n";

export const PyVersioningAddData = "# Add more data\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\nmore_data = [\n    {\n        \"id\": 4,\n        \"author\": \"Richard Daniel Sanchez\",\n        \"quote\": \"That's the way the news goes!\",\n    },\n    {\"id\": 5, \"author\": \"Morty\", \"quote\": \"Aww geez, Rick!\"},\n]\ntable.add(more_data)\n";

export const PyVersioningBasicSetup = "import lancedb\nimport numpy as np\nimport pandas as pd\nimport pyarrow as pa\n\n# Connect to LanceDB\ndb = tmp_db\n\n# Create a table with initial data\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n    {\"id\": 2, \"author\": \"Morty\", \"quote\": \"Rick, what's going on?\"},\n    {\n        \"id\": 3,\n        \"author\": \"Richard\",\n        \"quote\": \"I turned myself into a pickle, Morty!\",\n    },\n]\n\n# Define schema\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\n\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n";

export const PyVersioningCheckInitialVersion = "# View the initial version\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\nversions = table.list_versions()\nprint(f\"Number of versions after creation: {len(versions)}\")\nprint(f\"Current version: {table.version}\")\n";

export const PyVersioningCheckVersionsAfterMod = "# Check versions after modifications\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\ntable.add([{\"id\": 2, \"author\": \"Morty\", \"quote\": \"Aww geez, Rick!\"}])\n\nversions = table.list_versions()\nversion_count_after_mod = len(versions)\nversion_after_mod = table.version\nprint(f\"Number of versions after modifications: {version_count_after_mod}\")\nprint(f\"Current version: {version_after_mod}\")\n";

export const PyVersioningCheckoutLatest = "# Go back to the latest version\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\ntable.checkout_latest()\n";

export const PyVersioningDeleteData = "# Let's delete data from the table\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n    {\"id\": 2, \"author\": \"Morty\", \"quote\": \"Aww geez, Rick!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\ntable.delete(\"author != 'Richard Daniel Sanchez'\")\nrows_after_deletion = table.count_rows()\nprint(f\"Number of rows after deletion: {rows_after_deletion}\")\n";

export const PyVersioningListAllVersions = "# Let's see all versions\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\nversions = table.list_versions()\nfor v in versions:\n    print(f\"Version {v['version']}, created at {v['timestamp']}\")\n";

export const PyVersioningRollback = "# Let's roll back to before we added the vector column\n# We'll use the version after modifications but before adding embeddings\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\nversion_after_mod = table.version\ntable.add([{\"id\": 2, \"author\": \"Morty\", \"quote\": \"Aww geez, Rick!\"}])\n\ntable.restore(version_after_mod)\n\n# Notice we have one more version now, not less!\nversions = table.list_versions()\nversion_count_after_rollback = len(versions)\nprint(f\"Total number of versions after rollback: {version_count_after_rollback}\")\n";

export const PyVersioningUpdateData = "# Update author names to be more specific\ndb = tmp_db\ntable_name = \"quotes_versioning_example\"\ndata = [\n    {\"id\": 1, \"author\": \"Richard\", \"quote\": \"Wubba Lubba Dub Dub!\"},\n]\nschema = pa.schema(\n    [\n        pa.field(\"id\", pa.int64()),\n        pa.field(\"author\", pa.string()),\n        pa.field(\"quote\", pa.string()),\n    ]\n)\ntable = db.create_table(table_name, data, schema=schema, mode=\"overwrite\")\n\ntable.update(where=\"author='Richard'\", values={\"author\": \"Richard Daniel Sanchez\"})\nrows_after_update = table.count_rows()\nprint(f\"Number of rows after update: {rows_after_update}\")\n";

