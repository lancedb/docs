{/* Auto-generated by scripts/mdx_snippets_gen.py. Do not edit manually. */}

export const PyFtsIndexCreate = "import lancedb\n\ndb = tmp_db\ntable_name = \"fts_index_create\"\ntable = db.open_table(table_name)\ntable.create_fts_index(\"text\")\n";

export const PyFtsIndexWait = "index_name = \"text_idx\"\ntable.wait_for_index([index_name])\n";

export const PyGpuIndexCuda = "table.create_index(\n    num_partitions=256,\n    num_sub_vectors=96,\n    accelerator=\"cuda\",\n)\n";

export const PyGpuIndexMps = "table.create_index(\n    num_partitions=256,\n    num_sub_vectors=96,\n    accelerator=\"mps\",\n)\n";

export const PyReindexingIncremental = "import lancedb\n\ndb = tmp_db\ntable = db.open_table(\"reindexing_incremental\")\ntable.add([{\"vector\": [3.1, 4.1], \"text\": \"Frodo was a happy puppy\"}])\ntable.optimize()\n";

export const PyScalarIndexBuild = "import lancedb\n\ndb = tmp_db\ntbl = db.open_table(\"scalar_index_build\")\ntbl.create_scalar_index(\"book_id\")\ntbl.create_scalar_index(\"publisher\", index_type=\"BITMAP\")\n";

export const PyScalarIndexFilter = "import lancedb\n\ndb = tmp_db\ntable = db.open_table(\"books\")\nresult = table.search().where(\"book_id = 2\").limit(10).to_pandas()\n";

export const PyScalarIndexOptimize = "table.add([{\"vector\": [7, 8], \"book_id\": 4}])\ntable.optimize()\n";

export const PyScalarIndexPrefilter = "import lancedb\n\ndb = tmp_db\ntable = db.open_table(\"book_with_embeddings\")\ntable.search([1.2] * 2) \\\n    .where(\"book_id != 3\") \\\n    .limit(10) \\\n    .to_pandas()\n";

export const PyScalarIndexUuidData = "import uuid\n\ndef generate_random_string(length=10):\n    charset = string.ascii_letters + string.digits\n    return \"\".join(random.choices(charset, k=length))\n\ndef generate_uuids(num_items):\n    return [uuid.uuid4().bytes for _ in range(num_items)]\n\nn = 10\nuuids = generate_uuids(n)\nnames = [generate_random_string() for _ in range(n)]\n";

export const PyScalarIndexUuidTable = "import lancedb\n\ndb = tmp_db\nuuid_array = pa.array(uuids, pa.binary(16))\nname_array = pa.array(names, pa.string())\nextension_array = pa.ExtensionArray.from_storage(UuidType(), uuid_array)\nschema = pa.schema(\n    [\n        pa.field(\"id\", UuidType()),\n        pa.field(\"name\", pa.string()),\n    ]\n)\ndata_table = pa.Table.from_arrays([extension_array, name_array], schema=schema)\ntable_name = \"index-on-uuid-test\"\ntable = db.create_table(table_name, data=data_table, mode=\"overwrite\")\n";

export const PyScalarIndexUuidType = "import pyarrow as pa\n\nclass UuidType(pa.ExtensionType):\n    def __init__(self):\n        super().__init__(pa.binary(16), \"my.uuid\")\n\n    def __arrow_ext_serialize__(self):\n        return b\"uuid-metadata\"\n\n    @classmethod\n    def __arrow_ext_deserialize__(cls, storage_type, serialized):\n        return UuidType()\n\npa.register_extension_type(UuidType())\n";

export const PyScalarIndexUuidUpsert = "new_users = [\n    {\"id\": uuid.uuid4().bytes, \"name\": \"Bobby\"},\n    {\"id\": uuid.uuid4().bytes, \"name\": \"Charlie\"},\n]\n\ntable.merge_insert(\"id\") \\\n    .when_matched_update_all() \\\n    .when_not_matched_insert_all() \\\n    .execute(new_users)\n";

export const PyScalarIndexUuidWait = "table.create_scalar_index(\"id\")\nindex_name = \"id_idx\"\ntable.wait_for_index([index_name])\n";

export const PyScalarIndexWait = "index_name = \"label_idx\"\ntable.wait_for_index([index_name])\n";

export const PyVectorIndexBinaryAddData = "table.add(data)\n";

export const PyVectorIndexBinaryBuildIndex = "table.create_index(\n    metric=\"hamming\",\n    vector_column_name=\"vector\",\n    index_type=\"IVF_FLAT\",\n)\n";

export const PyVectorIndexBinarySchema = "table = tmp_db.create_table(table_name, schema=schema, mode=\"overwrite\")\n";

export const PyVectorIndexBinarySearch = "query = np.random.randint(0, 2, size=ndim)\nquery = np.packbits(query)\ndf = table.search(query).metric(\"hamming\").limit(10).to_pandas()\ndf.vector = df.vector.apply(np.unpackbits)\n";

export const PyVectorIndexBuildHnsw = "table.create_index(index_type=\"IVF_HNSW_SQ\")\n";

export const PyVectorIndexBuildIvf = "table.create_index(\n    metric=\"cosine\",\n    vector_column_name=\"keywords_embeddings\",\n)\n";

export const PyVectorIndexCheckStatus = "import time\n\nindex_name = \"keywords_embeddings_idx\"\ntable.wait_for_index([index_name])\nprint(table.index_stats(index_name))\n";

export const PyVectorIndexConfigureIvf = "table.create_index(metric=\"l2\", num_partitions=16, num_sub_vectors=4)\n";

export const PyVectorIndexQueryHnsw = "tbl = table\ntbl.search(np.random.random((16))) \\\n    .limit(2) \\\n    .to_pandas()\n";

export const PyVectorIndexQueryIvf = "tbl = table\ntbl.search(np.random.random((1536))) \\\n    .limit(2) \\\n    .nprobes(20) \\\n    .refine_factor(10) \\\n    .to_pandas()\n";

export const PyVectorIndexSetup = "import lancedb\n\ndb = tmp_db\ntable_name = \"vector_index_setup\"\ntable = db.open_table(table_name)\n";

