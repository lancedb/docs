{/* Auto-generated by scripts/mdx_snippets_gen.py. Do not edit manually. */}

export const RsImports = "\nuse std::{iter::once, sync::Arc};\n\nuse arrow_array::{Float64Array, Int32Array, RecordBatch, RecordBatchIterator, StringArray};\nuse arrow_schema::{DataType, Field, Schema};\nuse futures::StreamExt;\nuse lancedb::{\n    arrow::IntoArrow,\n    connect,\n    embeddings::{openai::OpenAIEmbeddingFunction, EmbeddingDefinition, EmbeddingFunction},\n    query::{ExecutableQuery, QueryBase},\n    Result,\n};\n";

export const RsOpenaiEmbeddings = "#[tokio::main]\nasync fn main() -> Result<()> {\n    let tempdir = tempfile::tempdir().unwrap();\n    let tempdir = tempdir.path().to_str().unwrap();\n    let api_key = std::env::var(\"OPENAI_API_KEY\").expect(\"OPENAI_API_KEY is not set\");\n    let embedding = Arc::new(OpenAIEmbeddingFunction::new_with_model(\n        api_key,\n        \"text-embedding-3-large\",\n    )?);\n\n    let db = connect(tempdir).execute().await?;\n    db.embedding_registry()\n        .register(\"openai\", embedding.clone())?;\n\n    let table = db\n        .create_table(\"vectors\", make_data())\n        .add_embedding(EmbeddingDefinition::new(\n            \"text\",\n            \"openai\",\n            Some(\"embeddings\"),\n        ))?\n        .execute()\n        .await?;\n\n    let query = Arc::new(StringArray::from_iter_values(once(\"something warm\")));\n    let query_vector = embedding.compute_query_embeddings(query)?;\n    let mut results = table\n        .vector_search(query_vector)?\n        .limit(1)\n        .execute()\n        .await?;\n\n    let rb = results.next().await.unwrap()?;\n    let out = rb\n        .column_by_name(\"text\")\n        .unwrap()\n        .as_any()\n        .downcast_ref::<StringArray>()\n        .unwrap();\n    let text = out.iter().next().unwrap().unwrap();\n    println!(\"Closest match: {}\", text);\n    Ok(())\n}\n";

